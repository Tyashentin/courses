{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import random\n",
    "\n",
    "random.seed(137)\n",
    "rest = random.random()\n",
    "\n",
    "def weight(word):\n",
    "    # overfitted\n",
    "    if word == 'lerxst@wam.umd.edu':\n",
    "        return 100.0\n",
    "    if word == 'car':\n",
    "        return random.random()\n",
    "    if word == 'dog':\n",
    "        return - random.random()\n",
    "    return random.random()\n",
    "\n",
    "def has(word, text):\n",
    "    return word in text \n",
    "\n",
    "def feature(index):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applied Machine Learning\n",
    "\n",
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap\n",
    "\n",
    "- We have some dataset\n",
    "- We identify the problem and define the loss function\n",
    "- Then we minimize the total loss (empirical risk, or objective) using available (training) data\n",
    "- We vary parameters to minimize the objective function\n",
    "- The minimizing parameters are then used to predict unknown values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A text classification problem\n",
    "\n",
    "Lets consider the **20 newsgroups** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "----\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "text, label = data['data'][0], data['target_names'][data['target'][0]]\n",
    "print(label)\n",
    "print('----')\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A linear model for classification\n",
    "\n",
    "Let us consider a function that tells if the `text` comes from `rec.autos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48246169468192845"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight('car')*has('car', text) + weight('dog')*has('dog', text) + rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively say `car` is `0` and `dog` is `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6520663252475314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight(0)*feature(0) + weight(1)*feature(1) + rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How do we find those `weight` ($w$) for all the words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "- Last time we used `opt.fmin` and it magically found the solution\n",
    "- The method is simple though\n",
    "- Start with random weights $w_0$\n",
    "- Iterate: $w_{i+1} = w_{i} - \\alpha \\times \\nabla \\mathsf{objective}(w_i)$\n",
    "- All we need to know is the gradient of objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient of loss\n",
    "\n",
    "- Last time we considered a regression problem and used $(y-p)^2$\n",
    "- The gradient w.r.t $p$ is obvious: $- 2 (y - p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient check\n",
    "\n",
    "How can we ensure the gradient is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.39999999999999997, -0.400000000000001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(y, p):\n",
    "    return (y-p)**2\n",
    "\n",
    "def gradient(y, p):\n",
    "    return -2*(y-p)\n",
    "\n",
    "p = 0.1\n",
    "y = 0.3\n",
    "eps = 0.001\n",
    "gradient(y, p), (loss(y, p+eps) - loss(y, p-eps)) / (2*eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7165157020383032\n",
      "1 0.6332125616306425\n",
      "2 0.566570049304514\n",
      "3 0.5132560394436112\n",
      "4 0.47060483155488897\n"
     ]
    }
   ],
   "source": [
    "current_p = random.random()\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(5):\n",
    "    current_p = current_p - alpha*gradient(y, current_p)\n",
    "    print(i, current_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_p = random.random()\n",
    "alpha = 0.1\n",
    "\n",
    "xs = list(range(20))\n",
    "ys = []\n",
    "for _ in xs:\n",
    "    current_p = current_p - alpha*gradient(y, current_p)\n",
    "    ys.append(current_p)\n",
    "    \n",
    "plt.plot(xs, ys); plt.hlines(y, xs[0], xs[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification loss\n",
    "\n",
    "- We will use something called **logistic loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 144.26950408889635)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(y, p):\n",
    "    return np.log2(1.0 + np.exp(-y*p))\n",
    "    \n",
    "loss(-1, -100.0), loss(-1, +100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Regression in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.78909052, -9.69139956]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.SGDClassifier(loss='log', tol=1e-6)\n",
    "example_1 = [1,0]; label_1 = [1]\n",
    "example_2 = [0,1]; label_2 = [0]\n",
    "model.fit([example_1, example_2], np.ravel([label_1, label_2]))\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "- We can always come up with a model that fits data perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight('lerxst@wam.umd.edu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For some reason that's not what we want. Why?\n",
    "- First, we need to measure if such a thing happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting the data\n",
    "\n",
    "- Obviously we should not test what we fit against\n",
    "- We should fit (train) the model on some part of data\n",
    "- Next, we check the model against the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave-on-out\n",
    "\n",
    "- Generate as many samples as there are examples\n",
    "- Gives you a good estimate if you don't have a lot of data\n",
    "- Gets impractical on huge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4] [0]\n",
      "[0 2 3 4] [1]\n",
      "[0 1 3 4] [2]\n",
      "[0 1 2 4] [3]\n",
      "[0 1 2 3] [4]\n"
     ]
    }
   ],
   "source": [
    "loo = sklearn.model_selection.LeaveOneOut()\n",
    "for train, test in loo.split([1,2,3,4,5]):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross validation\n",
    "\n",
    "- Split the dataset into a few (say 5) non-overlapping parts\n",
    "- Four parts go to training data and one part goes to test data\n",
    "- Do the above 5 times to train the model and test it\n",
    "- Makes a decent way to *detect* overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross validation in sklearn\n",
    "\n",
    "Let's consider indices of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5] [0 1]\n",
      "[0 1 4 5] [2 3]\n",
      "[0 1 2 3] [4 5]\n"
     ]
    }
   ],
   "source": [
    "xval = sklearn.model_selection.KFold(n_splits=3)\n",
    "for train, test in xval.split([1,2,3,4,5,6]):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This thing is an ill-posed problem\n",
    "\n",
    "- A mathematical problem is ill-posed when the solution is not unique\n",
    "- That's exactly the case of regression/classification/...\n",
    "- We need to make the problem well-posed: *regularization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Structural risk minimization\n",
    "\n",
    "- Structural risk is empirical risk plus regularizer\n",
    "- Instead of minimizing empirical risk we find some tradeoff\n",
    "- Regularizer is a function of model we get\n",
    "- $\\mathsf{objective} = \\mathsf{loss} + \\mathsf{regularizer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularizer\n",
    "\n",
    "- A functions that reflects the complexity of a model\n",
    "- What is the complexity of a set of 'if ... then'?\n",
    "- Not obvious for linear model but easy to invent something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\ell_1$ regularizer\n",
    "\n",
    "- Derivative is const\n",
    "- Forces weight to be zero if it doesn't hurt performance much \n",
    "- Use if you believe some features are useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = sklearn.linear_model.SGDClassifier(loss='log', penalty='l1');\n",
    "regression_model = sklearn.linear_model.SGDRegressor(penalty='l1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\ell_2$ regularizer\n",
    "\n",
    "- Derivative is linear\n",
    "- Forces weights to get *similar* magnitude if it doesn't hurt performance much\n",
    "- Use if you believe all features are more or less important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = sklearn.linear_model.SGDClassifier(loss='log', penalty='l2');\n",
    "regression_model = sklearn.linear_model.SGDRegressor(penalty='l2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elastic net\n",
    "\n",
    "- Just a weighted sum of $\\ell_1$ and $\\ell_2$ regularizers\n",
    "- An attempt to get useful properties of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = sklearn.linear_model.SGDRegressor(penalty='elasticnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of linearity\n",
    "\n",
    "- In low-dimensional spaces linear models are not very 'powerful' (can we define that?)\n",
    "- The higher dimensionality, the more powerful linear model becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sparse features\n",
    "\n",
    "- We say features are sparse when most of the values are zero\n",
    "- Examples: visited hosts, movies that user liked, ...\n",
    "- Sparse features are efficient in high-dimensional setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, ..., 1, ..., 0, 0, 1, 0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding, hashing trick\n",
    "\n",
    "- One way to encode categorical things like visited hosts\n",
    "- We enumerate all the hosts\n",
    "- We put 1 to position of every host, 0 otherwise\n",
    "- Hashing trick: instead of enumerating them just hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4716215151074022774\n",
      "5494\n"
     ]
    }
   ],
   "source": [
    "print(hash('hse.ru'))\n",
    "print(hash('hse.ru') % 2**16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hashing vectorizer in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.70710678 0.         0.         0.         0.\n",
      "  0.         0.70710678 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.70710678 0.\n",
      "  0.         0.70710678 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=10, binary=True)\n",
    "features = vectorizer.fit_transform(['hello there', 'hey there'])\n",
    "print(features.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### When do we use linear models?\n",
    "\n",
    "- It is definitely the first thing to try if you have some text data\n",
    "- In general a good choice for any sparse data\n",
    "- This approach is pretty much the fastest one\n",
    "- Even if some method outperforms, you still get a good baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Self-assesment questions\n",
    "\n",
    "1. You noticed that your linear model learned a weight of **95.3** for the word `the`. *Is there a problem? Y/N*\n",
    "2. The train loss is **0.43** and the test loss is **0.39**. *Is it an example of ..? a) overfitting b) underfitting c) I don't know*\n",
    "3. You've got asically infinite amounts of data. *Do you have to use regularization? Y/N*\n",
    "4. You believe your dataset is pretty noisy and some features are broken. *You use a) L1 b) L2 c) no regularization* \n",
    "5. Why do we hash words? *a) it's simpler b) it's faster c) it's more reliable*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Homework 1\n",
    "\n",
    "- No score, just has to be done\n",
    "- Load dataset, create linear model, train, and explain the results\n",
    "- The template is provided: `HSE-AML-HW1.ipynb`\n",
    "- Hint: check the code examples for `KFold`, `HashingVectorizer`, `LogisticRegression`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
